{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib import gridspec\n",
    "import os\n",
    "import time\n",
    "from preprocessing import PreProcessing\n",
    "from model import SiameseNetwork\n",
    "import pandas as pd\n",
    "from tensorflow.contrib import learn\n",
    "import fasttext\n",
    "import faiss\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model_siamese_network/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pairs = pd.read_csv('./data_repository/questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_pairs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pairs.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['question1','question2','is_duplicate']\n",
    "question_pairs = question_pairs[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    try:\n",
    "        tk_x = x.lower()\n",
    "\n",
    "        # list of characters which needs to be replaced with space\n",
    "        space_replace_chars = ['?', ':', ',', '\"', '[', ']', '~', '*', ';', '!', '?', '(', ')', '{', '}', '@', '$',\n",
    "                               '#', '.', '-', '/']\n",
    "        tk_x = tk_x.translate({ord(x): ' ' for x in space_replace_chars})\n",
    "\n",
    "        non_space_replace_chars = [\"'\"]\n",
    "        tk_x = tk_x.translate({ord(x): '' for x in non_space_replace_chars})\n",
    "\n",
    "        # remove non-ASCII chars\n",
    "        tk_x = ''.join([c if ord(c) < 128 else '' for c in tk_x])\n",
    "\n",
    "        # replace all consecutive spaces with one space\n",
    "        tk_x = re.sub('\\s+', ' ', tk_x).strip()\n",
    "\n",
    "        # find all consecutive numbers present in the word, first converted numbers to * to prevent conflicts while replacing with numbers\n",
    "        regex = re.compile(r'([\\d])')\n",
    "        tk_x = regex.sub('*', tk_x)\n",
    "        nos = re.findall(r'([\\*]+)', tk_x)\n",
    "        # replace the numbers with the corresponding count like 123 by 3\n",
    "        for no in nos:\n",
    "            tk_x = tk_x.replace(no, \"<NUMBER>\", 1)\n",
    "\n",
    "        return tk_x.strip().lower()\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pairs['question1'] = question_pairs['question1'].apply(preprocess)\n",
    "question_pairs['question2'] = question_pairs['question2'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pairs = question_pairs.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pairs = question_pairs.drop_duplicates('question2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the story of kohinoor koh i noor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math &lt;number&gt;^ &lt;number...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>astrology i am a capricorn sun cap moon and ca...</td>\n",
       "      <td>im a triple capricorn sun moon and ascendant i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>should i buy tiago</td>\n",
       "      <td>what keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>how can i be a good geologist</td>\n",
       "      <td>what should i do to be a great geologist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>when do you use instead of</td>\n",
       "      <td>when do you use &amp; instead of and</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>motorola company can i hack my charter motorol...</td>\n",
       "      <td>how do i hack motorola dcx&lt;number&gt; for free in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "1   what is the story of kohinoor koh i noor diamond   \n",
       "2  how can i increase the speed of my internet co...   \n",
       "3   why am i mentally very lonely how can i solve it   \n",
       "4  which one dissolve in water quikly sugar salt ...   \n",
       "5  astrology i am a capricorn sun cap moon and ca...   \n",
       "6                                 should i buy tiago   \n",
       "7                      how can i be a good geologist   \n",
       "8                         when do you use instead of   \n",
       "9  motorola company can i hack my charter motorol...   \n",
       "\n",
       "                                           question2 is_duplicate  \n",
       "0  what is the step by step guide to invest in sh...            0  \n",
       "1  what would happen if the indian government sto...            0  \n",
       "2  how can internet speed be increased by hacking...            0  \n",
       "3  find the remainder when math <number>^ <number...            0  \n",
       "4             which fish would survive in salt water            0  \n",
       "5  im a triple capricorn sun moon and ascendant i...            1  \n",
       "6  what keeps childern active and far from phone ...            0  \n",
       "7           what should i do to be a great geologist            1  \n",
       "8                   when do you use & instead of and            0  \n",
       "9  how do i hack motorola dcx<number> for free in...            0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_pairs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/s0d02zy/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    }
   ],
   "source": [
    "# load vocab_processor\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor.restore(model_path+'vocab')\n",
    "item_db = np.asarray(list(vocab_processor.fit_transform(list(question_pairs['question2']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = fasttext.load_model(model_path+\"ft_skipgram_ws5_dim64.bin\")\n",
    "embeddings_lookup = []\n",
    "for word in list(vocab_processor.vocabulary_._mapping):\n",
    "    try:\n",
    "        embeddings_lookup.append(embeddings_model[str(word)])\n",
    "    except:\n",
    "        pass\n",
    "embeddings_lookup_ = np.asarray(embeddings_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of items to be indexed: \t 298249\n",
      "Embeddings dimension: \t\t 16\n"
     ]
    }
   ],
   "source": [
    "print('# of items to be indexed: \\t',item_db.shape[0])\n",
    "print('Embeddings dimension: \\t\\t',item_db.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "embedding_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(feed_data):\n",
    "    checkpoint_file = tf.train.latest_checkpoint(model_path)\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            # Load the saved meta graph and restore variables\n",
    "            saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "            saver.restore(sess, checkpoint_file)\n",
    "\n",
    "            # Get the placeholders from the graph by name\n",
    "            anchor_input = graph.get_operation_by_name(\"left_input\").outputs[0]\n",
    "\n",
    "            # Tensors we want to evaluate\n",
    "            predictions = graph.get_operation_by_name(\"output/output_embedding\").outputs[0]\n",
    "\n",
    "            # Collect the predictions here\n",
    "            all_predictions = []\n",
    "\n",
    "            batch_predictions = sess.run(predictions, {anchor_input: feed_data})\n",
    "    return batch_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_pairs_list = list(question_pairs['question2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find k nearest neighbour using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Vector representation for each training images and normalize those\n",
    "def generate_db_normed_vectors():\n",
    "    train_vectors = model_output(item_db)\n",
    "    normalized_train_vectors = train_vectors/np.linalg.norm(train_vectors,axis=1).reshape(-1,1)\n",
    "    return normalized_train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find k nearest neighbour using cosine similarity\n",
    "def find_k_nn(normalized_train_vectors,vec,k):\n",
    "    dist_arr = np.matmul(normalized_train_vectors, vec.T)\n",
    "    print(-1*np.sort(-dist_arr.flatten())[:k])\n",
    "    print(max(dist_arr.flatten()))\n",
    "    return np.argsort(-dist_arr.flatten())[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/s0d02zy/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./model_siamese_network/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "normalized_training_vectors = generate_db_normed_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB indexing done...\n"
     ]
    }
   ],
   "source": [
    "# Building faiss index\n",
    "db_index = faiss.IndexFlatIP(embedding_dim)  # \n",
    "db_index.add(normalized_training_vectors)  # add vectors to the index\n",
    "print('DB indexing done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_item(query, k=1):\n",
    "    query = [query,'milk']\n",
    "    stime = time.time()\n",
    "    query = [query[0].lower(),query[1].lower()]\n",
    "    input_queries = np.asarray(list(vocab_processor.fit_transform(query)))\n",
    "    search_vector = model_output([input_queries[0]])\n",
    "    normalized_search_vec = search_vector/np.linalg.norm(search_vector)\n",
    "    s_time = time.time()\n",
    "    # candidate_index_i = find_k_nn(normalized_training_vectors, normalized_search_vec, k)\n",
    "    _, candidate_index = db_index.search(normalized_search_vec,k)\n",
    "    candidate_index = candidate_index[0]\n",
    "    print('Total time to find nn: {:0.2f} ms'.format((time.time()-s_time)*1000))    \n",
    "    print('------------------------------------------------------')\n",
    "    print('Query: ',query[0])\n",
    "    print('------------------------------------------------------')\n",
    "    return candidate_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_wise_similarity(_left,_right):\n",
    "    similarity_score = []\n",
    "    left_queries = np.asarray(list(vocab_processor.fit_transform(_left)))\n",
    "    right_queries = np.asarray(list(vocab_processor.fit_transform(_right)))\n",
    "    left_vectors = model_output(left_queries)\n",
    "    right_vectors = model_output(right_queries)\n",
    "    \n",
    "    normalized_left_vectors = left_vectors/np.linalg.norm(left_vectors,axis=1).reshape(-1,1)\n",
    "    normalized_right_vectors = right_vectors/np.linalg.norm(right_vectors,axis=1).reshape(-1,1)\n",
    "    for i in range(0,len(normalized_left_vectors)):\n",
    "        similarity_score.append(np.matmul(normalized_left_vectors[i],normalized_right_vectors[i].T))\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_siamese_network/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model_siamese_network/model.ckpt\n",
      "Similarity Score:  [0.85194063]\n"
     ]
    }
   ],
   "source": [
    "question1 = \"How could Quora attract initial users\"\n",
    "question2 = \"When did Quora start and how did it attract users\"\n",
    "similarity_score = get_pair_wise_similarity([question1.lower()],[question2.lower()])\n",
    "print('Similarity Score: ', similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Search [Most similar k questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_siamese_network/model.ckpt\n",
      "Total time to find nn: 5.83 ms\n",
      "------------------------------------------------------\n",
      "Query:  is it healthy to eat egg whites every day\n",
      "------------------------------------------------------\n",
      "is it bad for health to eat eggs every day\n",
      "is it healthy to eat once a day\n",
      "is it unhealthy to eat bananas every day\n",
      "is it healthy to eat bread every day\n",
      "is it healthy to eat fish every day\n",
      "what high protein foods are good for breakfast\n",
      "how do you drink more water every day\n",
      "what will happen if i drink a gallon of milk every day\n",
      "is it healthy to eat one chicken every day\n",
      "is it healthy to eat a whole avocado every day\n"
     ]
    }
   ],
   "source": [
    "query = \"Is it healthy to eat egg whites every day\"\n",
    "candidate_index = get_top_k_item(query.lower(), 10)\n",
    "for index in candidate_index:\n",
    "    print(similar_pairs_list[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                           ---------------------- *** --------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
